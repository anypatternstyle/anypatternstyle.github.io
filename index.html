<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap"
      rel="stylesheet">
<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen"/>

<html lang="en">
<head>
  	<title>AnyPattern</title>
      <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/
          if you update and want to force Facebook to re-scrape. -->
  	<meta property="og:image" content="./resources/AnyPattern.jpg"/>
  	<meta property="og:title" content="AnyPattern: Towards In-context Image Copy Detection" />
  	<meta property="og:description" content="This paper explores in-context learning for image copy detection (ICD), i.e., prompting an ICD model to identify replicated images with new tampering patterns without the need for additional training. The prompts (or the contexts) are from a small set of image-replica pairs that reflect the new patterns and are used at inference time. Such in-context ICD has good realistic value, because it requires no fine-tuning and thus facilitates fast reaction against the emergence of unseen patterns. To accommodate the “seen → unseen” generalization scenario, we construct the first large-scale pattern dataset named AnyPattern, which has the largest number of tamper patterns (90 for training and 10 for testing) among all the existing ones. We benchmark AnyPattern with popular ICD methods and reveal that existing methods barely generalize to novel tamper patterns. We further propose a simple in-context ICD method named ImageStacker. ImageStacker learns to select the most representative image-replica pairs and employs them as the pattern prompts in a stacking manner (rather than the popular concatenation manner). Experimental results show (1) training with our large-scale dataset substantially benefits pattern generalization (+26.66% μAP), (2) the proposed ImageStacker facilitates effective in-context ICD (another round of +16.75% μAP), and (3) AnyPattern enables in-context ICD, i.e. without such a large-scale dataset, in-context learning does not emerge even with our ImageStacker." />
    <!-- Twitter automatically scrapes this. Go to https://cards-dev.twitter.com/validator?
        if you update and want to force Twitter to re-scrape. -->
    <meta property="twitter:card"          content="summary" />
    <meta property="twitter:title"         content="AnyPattern: Towards In-context Image Copy Detection" />
    <meta property="twitter:description"   content="This paper explores in-context learning for image copy detection (ICD), i.e., prompting an ICD model to identify replicated images with new tampering patterns without the need for additional training. The prompts (or the contexts) are from a small set of image-replica pairs that reflect the new patterns and are used at inference time. Such in-context ICD has good realistic value, because it requires no fine-tuning and thus facilitates fast reaction against the emergence of unseen patterns. To accommodate the “seen → unseen” generalization scenario, we construct the first large-scale pattern dataset named AnyPattern, which has the largest number of tamper patterns (90 for training and 10 for testing) among all the existing ones. We benchmark AnyPattern with popular ICD methods and reveal that existing methods barely generalize to novel tamper patterns. We further propose a simple in-context ICD method named ImageStacker. ImageStacker learns to select the most representative image-replica pairs and employs them as the pattern prompts in a stacking manner (rather than the popular concatenation manner). Experimental results show (1) training with our large-scale dataset substantially benefits pattern generalization (+26.66% μAP), (2) the proposed ImageStacker facilitates effective in-context ICD (another round of +16.75% μAP), and (3) AnyPattern enables in-context ICD, i.e. without such a large-scale dataset, in-context learning does not emerge even with our ImageStacker." />
    <meta property="twitter:image"         content="./resources/AnyPattern.jpg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Add your Google Analytics tag here -->
    <script async
            src="https://www.googletagmanager.com/gtag/js?id=UA-97476543-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

</head>

<body>
<div class="container">
    <div class="title">
        AnyPattern: Towards In-context Image Copy Detection
    </div>

    <div class="venue">
        Arxiv 2024
    </div>

    <br><br>

    <div class="author">
        <a href="https://wangwenhao0716.github.io/">Wenhao Wang</a><sup>1</sup>
    </div>
    <div class="author">
        <a href="https://yifansun-reid.github.io/">Yifan Sun</a><sup>2</sup>
    </div>
      <br>
    <div class="author">
        <a href="https://scholar.google.com/citations?user=jDsfBUwAAAAJ&hl=zh-CN">Zhentao Tan</a><sup>2,3</sup>
    </div>
    <div class="author">
        <a href="https://scholar.google.com/citations?user=RMSuNFwAAAAJ&hl=en">Yi Yang</a><sup>4</sup>
    </div>

    <br><br>

    <div class="affiliation"><sup>1&nbsp;</sup>University of Technology Sydney</div>
    <div class="affiliation"><sup>2&nbsp;</sup>Baidu Inc.</div>
    <div class="affiliation"><sup>3&nbsp;</sup>Peking University</div>
    <div class="affiliation"><sup>4&nbsp;</sup>Zhejiang University</div>

    <br><br>

    <div class="links"><a href="https://arxiv.org/pdf/2404.13788.pdf">[Paper]</a></div>
    <div class="links"><a href="https://huggingface.co/datasets/WenhaoWang/AnyPattern">[Data]</a></div>
    <div class="links"><a href="https://github.com/WangWenhao0716/AnyPattern">[Code]</a></div>

    <br><br>

    <img style="width: 80%;" src="./resources/AnyPattern.jpg" alt="Teaser figure."/>
    <br>
    <p style="width: 80%;">
         Top: The comparison between the standard updating process of Image Copy Detection (ICD) and the proposed in-context ICD. Unlike the standard updating approach, our in-context ICD eliminates the need for fine-tuning, making it more efficient. Bottom: AnyPattern is the first large-scale pattern dataset, featuring 90 base and 10 novel patterns. Using 90 base patterns, we generate a training dataset containing 10 million images. 
    </p>

    <br><br>
    <hr>

    <h1>Abstract</h1>
    <p style="width: 80%;">
        This paper explores in-context learning for image copy detection (ICD), i.e., prompting an ICD model to identify replicated images with new tampering patterns without the need for additional training. The prompts (or the contexts) are from a small set of image-replica pairs that reflect the new patterns and are used at inference time. Such in-context ICD has good realistic value, because it requires no fine-tuning and thus facilitates fast reaction against the emergence of unseen patterns. To accommodate the “seen → unseen” generalization scenario, we construct the first large-scale pattern dataset named AnyPattern, which has the largest number of tamper patterns (90 for training and 10 for testing) among all the existing ones. We benchmark AnyPattern with popular ICD methods and reveal that existing methods barely generalize to novel tamper patterns. We further propose a simple in-context ICD method named ImageStacker. ImageStacker learns to select the most representative image-replica pairs and employs them as the pattern prompts in a stacking manner (rather than the popular concatenation manner). Experimental results show (1) training with our large-scale dataset substantially benefits pattern generalization (+26.66% μAP), (2) the proposed ImageStacker facilitates effective in-context ICD (another round of +16.75% μAP), and (3) AnyPattern enables in-context ICD, i.e. without such a large-scale dataset, in-context learning does not emerge even with our ImageStacker.
    </p>

    <br><br>
    <hr>
     

    <h1>In-context Image Copy Detection</h1>
    <img style="width: 80%;" src="./resources/incontext.png"
         alt="In-context Image Copy Detection figure"/>
    <br>
    <p style="width: 80%;">
        The illustration for our in-context Image Copy Detection (ICD) with AnyPattern. In-context ICD necessitates a well-trained ICD model to be prompted to novel patterns with the assistance of a few image-replica pairs and without any fine-tuning process. In realistic scenarios, this setup is highly practical as it provides a feasible solution for a deployed ICD system faced with unseen patterns.
    </p>
      
    <br><br>
    <hr>
      
    <h1>Method Overview</h1>
    <img style="width: 80%;" src="./resources/method.png"
         alt="Method overview figure"/>
    <br>
      <p style="width: 80%;">
        The proposed ImageStacker includes: (a) prompt selection fetches the most representative image-replica pair from the whole pool for a given query, and (b) prompting design stacks the selected image-replica pair onto a query along the channel dimension, and thus the image-replica pair conditions the feed-forward process. In (c), we show how to unify prompt selection and prompting design into one vision transformer.    
      </p>
    <br><br>
    <hr>

    <h1>AnyPattern Enables In-context ICD</h1>
    <img style="width: 80%;" src="./resources/result.png"
         alt="Results figure"/>
      <p style="width: 80%;">
       In-context learning does not emerge when using SmallPattern and ImageNet-pretrained models: comparing against baseline with 16.18% in μAP, ImageStacker only achieves 15.28% in μAP. 
    </p>
   <br><br>
    <hr>

    <h1>Paper</h1>
    <div class="paper-thumbnail">
        <a href="https://arxiv.org">
            <img class="layered-paper-big" width="100%" src="./resources/paper.png" alt="Paper thumbnail"/>
        </a>
    </div>
    <div class="paper-info">
        <h3>AnyPattern: Towards In-context Image Copy Detection</h3>
        <p>Wenhao Wang, Yifan Sun, Zhentao Tan, and Yi Yang</p>
        <p>Arxiv 2024</p>
        <pre><code>@inproceedings{
    wang2024AnyPattern,
    title={AnyPattern: Towards In-context Image Copy Detection},
    author={Wang, Wenhao and Sun, Yifan and Tan, Zhentao and Yang, Yi},
    booktitle={arXiv preprint arXiv:2404.13788},
    year={2024},
}</code></pre>
    </div>

    <br><br>
    <hr>

   <h1>Contact</h1>
    <p style="width: 80%;">
        If you have any questions, feel free to contact <a href="https://wangwenhao0716.github.io/">Wenhao Wang</a> (wangwenhao0716@gmail.com).
    </p>

   <br><br>
    <hr>

    <h1>Acknowledgements</h1>
    <p style="width: 80%;">
        This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful project</a>, and inherits the modifications made by <a href="https://github.com/jasonyzhang/webpage-template">Jason Zhang</a> and <a href="https://github.com/elliottwu/webpage-template">Shangzhe Wu</a>.
        The code can be found <a href="https://github.com/AnyPattern/anypattern.github.io">here</a>.
    </p>

    <br><br>
</div>

</body>

</html>
